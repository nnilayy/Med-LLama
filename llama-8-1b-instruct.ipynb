{"cells":[{"cell_type":"markdown","metadata":{},"source":["## LIBRARY INSTALLATION"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install evaluate peft transformers==4.42.0"]},{"cell_type":"markdown","metadata":{},"source":["## API KEYS"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import wandb\n","from huggingface_hub import HfApi\n","from kaggle_secrets import UserSecretsClient\n","\n","# LOADING API-KEYS\n","user_secrets = UserSecretsClient()\n","\n","# HUGGINGFACE LOGIN\n","hugging_face_token = user_secrets.get_secret(\"HUGGING_FACE_API_KEY\")\n","api = HfApi(token=hugging_face_token)\n","\n","# WANDB LOGIN\n","wandb_api_token = user_secrets.get_secret(\"WANDB_API_KEY\")\n","wandb.login(key = wandb_api_token)"]},{"cell_type":"markdown","metadata":{},"source":["## LOADING MODEL AND TOKENIZERS"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","# tokenizer.pad_token = tokenizer.eos_token\n","checkpoint = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint, token=hugging_face_token)\n","model = AutoModelForCausalLM.from_pretrained(checkpoint, \n","                                             device_map=\"auto\",\n","                                             torch_dtype=torch.float16,\n","                                             token=hugging_face_token,\n","                                            )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import TextStreamer\n","streamer = TextStreamer(\n","    tokenizer,\n","    skip_prompt=True,\n","    skip_special_tokens=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","# Load dataset\n","dataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\")\n","test_set = dataset[\"train\"]\n","\n","# Load model and tokenizer\n","checkpoint = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint, token=hugging_face_token)\n","model = AutoModelForCausalLM.from_pretrained(checkpoint, \n","                                             device_map=\"auto\",\n","                                             torch_dtype=torch.float16,\n","                                             token=hugging_face_token)\n","tokenizer.pad_token = tokenizer.eos_token\n","device = next(model.parameters()).device\n","\n","def collate_fn(batch):\n","    input_texts = [f\"Question: {item['question']}\\nAnswer:\" for item in batch]\n","    inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True)\n","    return {\n","        'inputs': inputs,\n","        'true_answers': [item['final_decision'] for item in batch]\n","    }\n","\n","batch_size = 8  # Adjust based on your GPU memory\n","dataloader = DataLoader(test_set, batch_size=batch_size, collate_fn=collate_fn)\n","\n","# Evaluation loop\n","results = []\n","total_batches = len(dataloader)\n","\n","model.eval()\n","for batch in tqdm(dataloader, total=total_batches, desc=\"Evaluating\"):\n","    inputs = batch['inputs']\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","    \n","    with torch.no_grad():\n","        outputs = model.generate(**inputs, max_length=1024)\n","    \n","    generated_answers = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    \n","    for true_answer, generated_answer in zip(batch['true_answers'], generated_answers):\n","        results.append({\n","            \"true_answer\": true_answer,\n","            \"generated_answer\": generated_answer\n","        })\n","\n","# Calculate metrics\n","correct = sum(1 for r in results if r[\"true_answer\"] in r[\"generated_answer\"])\n","accuracy = correct / len(results)\n","print(f\"Accuracy: {accuracy:.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## DATAHELPER CLASS"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# LOADING DATASET\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer, BertForSequenceClassification\n","checkpoint = \"bert-base-uncased\"\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint, padding_side=\"right\")\n","\n","dataset = load_dataset(\"glue\", \"mrpc\")\n","train_dataset = dataset['train']\n","test_dataset = dataset['test']\n","validation_dataset = dataset['validation']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from helper_classes.datahelper import DataHelper\n","\n","class CustomDataHelper(DataHelper):\n","    def handle_dataset(self):\n","        datasets_dict = self.datasets_dict\n","        for dataset_name, dataset in datasets_dict.items:\n","            sentence1 = dataset['sentence1']\n","            sentence2 = dataset['sentence2']\n","            dataset['input'] = dataset['sentence1'] + dataset['sentence2']\n","            self.handled_datasets_dict.update({dataset_name+\"_handled\":dataset})\n","        return self.handled_datasets_dict            \n","\n","datasets_dict = {\n","    \"train_dataset\": train_dataset,\n","    \"test_dataset\": test_dataset,\n","    \"validation_dataset\": validation_dataset\n","}\n","\n","dataset_configuration = {\n","    \"batch_size\": 32,\n","    \"shuffle\": True,\n","    \"return_tensors\": \"pt\",\n","    \"max_length\":128,\n","    \"padding\": True,\n","    \"truncation\": True\n","}\n","\n","column_configuration = {\n","    \"user_query_column\": \"input\",\n","    \"columns_to_tokenize\":\"sentence1\"\n","}\n","\n","# data_helper = CustomDataHelper()\n","# data_helper.handle_dataset()\n","data_helper = DataHelper()\n","data_helper.load_datasets_dict(datasets_dict)\n","data_helper.load_config_columns(column_configuration)\n","data_helper.set_dataset_config(dataset_configuration)\n","\n","# data_helper.load_tokenizer(tokenizer)\n","# tokenized_dataset = data_helper.tokenize_datasets()\n","dataloader = data_helper.datasets_to_dataloader()\n","dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Extracting Datasets\n","train_dataset = dataset['train']\n","test_dataset = dataset['test']\n","validation_dataset = dataset['validation']\n","datasets = [train_dataset, test_dataset, validation_dataset]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["datahelper = DataHelper(tokenizer=tokenizer, user_query_column = \"input\", columns_to_tokenize=\"training_input\")\n","\n","formatted_datasets = [datahelper.format_dataset(dataset) for dataset in datasets]\n","tokenized_datasets = [datahelper.tokenize_dataset(dataset) for dataset in formatted_datasets]\n","\n","train_dataset, test_dataset, validation_dataset = tokenized_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# tokenized_datasets\n","# datahelper.clean_up_dataset(base_dataset=dataset['train'], tokenized_dataset=tokenized_dataset)\n","# train_dataset = dataset['train'].map(preprocessing, batched=True, batch_size=32)\n","# train_dataset = train_dataset.remove_columns(['input', 'instruction', 'output', 'final_text'])\n","# train_dataset.set_format(type='pt', columns=['input_ids', 'attention_mask'], output_all_columns=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Trainer Code"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=1,\n","    per_device_train_batch_size=28,\n","    save_total_limit=1,\n","    eval_strategy=\"steps\",\n","    save_strategy=\"epoch\",\n","    save_steps = 100,\n","    # label_names = ['not_equivalent', 'equivalent'],\n","    fp16=torch.cuda.is_available()  # Use mixed precision if GPUs support it\n",")\n","\n","# Initialize Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset['train'],\n","    eval_dataset=dataset['validation'],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import warnings\n","import numpy as np\n","from time import time\n","from evaluate import load\n","from datasets import load_dataset\n","from transformers import DataCollatorWithPadding\n","from peft.utils import get_peft_model_state_dict\n","from transformers import TrainingArguments, Trainer\n","from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n","from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer, BertForSequenceClassification\n","\n","    \n","warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","from transformers import set_seed\n","set_seed(42)\n","\n","def main():\n","    def compute_metrics(eval_pred):\n","        logits, labels = eval_pred\n","        predictions = np.argmax(logits, axis=-1)\n","        return accuracy.compute(predictions=predictions, references=labels)\n","\n","    def encode(examples):\n","        output = tokenizer(examples['sentence1'], \n","                           examples['sentence2'], \n","                           truncation=True, \n","                           padding='max_length', \n","                           max_length=128,\n","                          )\n","        \n","        output['labels'] = examples['label']\n","        return output\n","\n","# MODEL\n","    checkpoint = \"bert-base-uncased\"\n","    model = AutoModelForSequenceClassification.from_pretrained(checkpoint,\n","                                                  #torch_dtype=torch.float16,\n","                                                 )\n","\n","#     peft_config = LoraConfig(inference_mode=False,\n","#                              r=32,\n","#                              lora_alpha = 512,\n","#                              lora_dropout = 0.1,\n","#                              bias=\"none\",\n","#                              peft_type = TaskType.SEQ_CLS, #\" CAUSAL_LM\"\n","#                              )\n","\n","#     model = prepare_model_for_kbit_training(model)\n","#     model = get_peft_model(model, peft_config)\n","#     model.print_trainable_parameters()\n","\n","# TYPICAL TRAINING CODE\n","    accuracy = load(\"accuracy\")\n","    tokenizer = AutoTokenizer.from_pretrained(checkpoint, padding_side=\"right\")\n","    tokenizer.pad_token = tokenizer.eos_token\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","    \n","#   DATASET PREP\n","    dataset = load_dataset(\"glue\", \"mrpc\")\n","    dataset = dataset.map(encode, batched=True)    \n","    dataset = dataset.remove_columns(['sentence1', 'sentence2', 'label', 'idx'])\n","    dataset.set_format(type='pt', columns=['input_ids', 'attention_mask', 'labels',], output_all_columns=True)\n","    data_collator = DataCollatorWithPadding(tokenizer)\n","    \n","        \n","# TRAINING ARGUMENTS\n","    training_args = TrainingArguments(\n","    # DIRECTORIES FOR SAVING AND LOGGING\n","        output_dir=\"/kaggle/working/glue_model_checkpointing_test-8\",\n","        logging_dir =  \"/kaggle/working/logs\", \n","    \n","    #  BASIC PARAMS\n","        num_train_epochs=5,\n","        fp16=True,\n","        seed=42,\n","        data_seed=42,\n","        \n","    # OPTIMIZER SETUP\n","        optim=\"rmsprop\",\n","        learning_rate=1e-4,\n","        lr_scheduler_type=\"cosine\",\n","        #lr_scheduler_kwargs={\"power\": 2.0},\n","        warmup_ratio=0.2,\n","        #warmup_steps=200,\n","        \n","    # DATA RELATED ARGUMENTS\n","        per_device_train_batch_size=16,\n","        per_device_eval_batch_size=16,\n","        dataloader_num_workers=4, # Reduces Training time by a decent percentage\n","        dataloader_pin_memory=True,\n","        dataloader_persistent_workers=True, \n","        ddp_find_unused_parameters=False,        \n","        \n","    # LOGGING\n","        logging_strategy=\"epoch\", # Logs the Training Loss\n","        label_names = ['labels'], # If Peft is off, keep this off doesnt do anything, if Peft is on, Logs the Validation Loss and Validation Accuracy\n","        #report_to = tensorboard\n","        \n","    # EVALUATION\n","        eval_strategy=\"epoch\", # Doesnt Evaluate the model per epoch, Reducing the training time\n","        #eval_steps        \n","        \n","    # SAVING TO HUB\n","        save_strategy=\"epoch\",\n","        save_total_limit=1,\n","        push_to_hub=True,\n","        hub_token = hugging_face_token,\n","        hub_strategy=\"every_save\",\n","        hub_model_id=\"nnilayy/glue_model_checkpointing_test-8\",\n","        \n","#     SAVING VRAM\n","#         torch_empty_cache_steps=40, #Clears vram cache during training after a few steps\n","#         gradient_checkpointing=True,\n","#         gradient_accumulation_steps=4,\n","    )\n","\n","# TRAINER CONSTRUCTOR\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=dataset[\"train\"],\n","        eval_dataset=dataset[\"test\"],\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","# Pushing Tokenizer, Model Card, Label Mapping to Hub \n","#     tokenizer.push_to_hub(\"nnilayy/glue_model_checkpointing_test-8\")\n","#     model.config.label2id = {'equivalent': 0, 'not_equivalent': 1}\n","#     model.config.id2label = {0: 'equivalent', 1: 'not_equivalent'}\n","#     model.config.push_to_hub(\"nnilayy/glue_model_checkpointing_test-8\")\n","\n","    trainer.train()\n","    model.save_pretrained(\"/kaggle/working/test-model-5\")\n","\n","if __name__ == \"__main__\":\n","    from accelerate import notebook_launcher\n","    notebook_launcher(main, num_processes=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer, BertForSequenceClassification\n","from datasets import load_dataset\n","checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint, padding_side=\"right\")\n","\n","def encode(examples):\n","    output = tokenizer(examples['sentence1'], \n","                       examples['sentence2'], \n","                       truncation=True, \n","                       padding='max_length', \n","                       max_length=128,\n","                      return_tensors=\"pt\")\n","    output['labels'] = examples['label']\n","    return output\n","\n","dataset = load_dataset(\"glue\", \"mrpc\")\n","val_dataset = dataset['validation']\n","val_dataset = val_dataset.map(encode, batched=True) \n","val_dataset = val_dataset.remove_columns(['sentence1', 'sentence2', 'label', 'idx'])\n","val_dataset.set_format(type='pt', columns=['input_ids', 'attention_mask', \"token_type_ids\",'labels',], output_all_columns=True)\n","val_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["validation_dataset = val_dataset\n","# test_dataset = val_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import set_seed\n","from peft import PeftConfig, PeftModelForSequenceClassification\n","\n","# set_seed(42)\n","\n","base_model_id = \"bert-base-uncased\"\n","fine_tuned_model_id = \"/kaggle/working/test-model-5/\"\n","base_model = AutoModelForSequenceClassification.from_pretrained(base_model_id).to(\"cuda\")\n","fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(fine_tuned_model_id).to(\"cuda\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## EVALUATOR CLASS"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tqdm import tqdm \n","from evaluate import load\n","from torch.utils.data import DataLoader\n","\n","# test_dataset = DataHelper(dataset)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n","\n","accuracy = load(\"accuracy\")\n","\n","labels, all_logits = [], []\n","for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n","    inputs = {k:v.to(\"cuda\") for k,v in batch.items()}\n","    with torch.no_grad():\n","        outputs = fine_tuned_model(**inputs)\n","    logits = outputs.logits\n","    predictions = torch.argmax(logits, dim=-1)\n","    all_logits.append(predictions)\n","    labels.append(inputs['labels'])\n","\n","labels = torch.cat(labels, dim=0)\n","all_logits = torch.cat(all_logits, dim=0)\n","\n","accuracy.compute(predictions = all_logits, references = labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# LOADING MODELS\n","from transformers import set_seed\n","from peft import PeftConfig, PeftModelForSequenceClassification\n","\n","base_model_id = \"bert-base-uncased\"\n","fine_tuned_model_id = \"/kaggle/working/test-model-5/\"\n","base_model = AutoModelForSequenceClassification.from_pretrained(base_model_id).to(\"cuda\")\n","fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(fine_tuned_model_id).to(\"cuda\")\n","\n","# LOADING METRICS\n","from evaluate import load\n","accuracy = load(\"accuracy\")\n","f1 = load(\"f1\")\n","recall = load(\"recall\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from helper_classes.evaluator import Evaluator\n","\n","models_dict = {\n","    \"fine_tuned_model\": fine_tuned_model,\n","    \"base_model\": base_model,\n","}\n","\n","metrics_dict = {\n","    \"accuracy\": accuracy,\n","    \"f1\": f1,\n","    \"recall\": recall,   \n","}\n","\n","datasets_dict = {\n","#     \"train_dataset\": train_dataset,\n","    \"test_dataset\": test_dataset,\n","    \"validation_dataset\": validation_dataset,\n","}\n","\n","\n","evaluator = Evaluator()\n","evaluator.set_device(\"cuda\")\n","evaluator.load_models_dict(models_dict)\n","evaluator.load_metrics_dict(metrics_dict)\n","evaluator.load_datasets_dict(datasets_dict)\n","\n","result = evaluator.evaluate_datasets()\n","result"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Code"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","import torch\n","import logging\n","\n","class Evaluate:\n","    def __init__(self, tokenizer, model):\n","        \n","        logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n","\n","        self.tokenizer = tokenizer\n","        self.model = model\n","        self.streamer = None\n","        self.model.generation_config.pad_token_id = self.tokenizer.pad_token_id\n","        self.model.generation_config.eos_token_id = self.tokenizer.eos_token_id\n","        \n","    def single_question_evaluate(self, question, return_prompt=False, stream_response=False):\n","        self.model.eval()\n","        with torch.no_grad():\n","            inputs = self.tokenizer(question, return_tensors=\"pt\").to(\"cuda\")\n","            output = self.model.generate(\n","                **inputs,\n","                max_new_tokens=1000,\n","                return_dict_in_generate=True,\n","                temperature=0.5,\n","                do_sample=True,\n","                top_k=50, \n","                num_beams=1,\n","                early_stopping=False,\n","                eos_token_id=self.tokenizer.eos_token_id,\n","                pad_token_id=self.tokenizer.pad_token_id,\n","                streamer=(self.streamer if stream_response else None),\n","            )\n","            \n","            if return_prompt:\n","                response = self.tokenizer.decode(output.sequences[0], skip_special_tokens=True)\n","            else:\n","                response = self.tokenizer.decode(output.sequences[:, inputs.input_ids.shape[1]:][0], skip_special_tokens=True)  \n","                \n","            return response\n","                \n","    def load_streamer(self, streamer):\n","        self.streamer = streamer\n","        return self.streamer\n","    \n","    def batch_evaluate(self, dataset, batch_size, return_prompt=False):\n","        pass\n","    \n","    def qbq_evaluate(self, dataset, return_prompt=False):\n","        model_responses = []\n","        self.model.eval()\n","        with tqdm(total=len(dataset), desc=\"Generating responses\", unit=\"question\") as pbar:\n","            for index in range(len(dataset)):\n","                with torch.no_grad():\n","                    question = dataset['training_input'][index]\n","                    inputs = self.tokenizer(question, return_tensors=\"pt\").to(\"cuda\")\n","                    output = self.model.generate(\n","                        **inputs,\n","                        max_new_tokens=1000,\n","                        return_dict_in_generate=True,\n","                        temperature=0.5,\n","                        do_sample=True,\n","                        top_k=50, \n","                        num_beams=1,\n","                        early_stopping=False,\n","                    )\n","                    if return_prompt:\n","                        response = self.tokenizer.decode(output.sequences[0], skip_special_tokens=True)\n","                    else:\n","                        response = self.tokenizer.decode(output.sequences[:, inputs.input_ids.shape[1]:][0], skip_special_tokens=True)\n","                        \n","                    model_responses.append(response)\n","                    pbar.update(1)\n","                    \n","        return model_responses\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
