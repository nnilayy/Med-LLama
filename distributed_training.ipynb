{
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/MedGPT/blob/main/distributed_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate datasets evaluate transformers"
      ],
      "metadata": {
        "_cell_guid": "57b902e9-7ca5-485b-a684-dd76d62125ad",
        "_uuid": "b5780f65-0694-4e20-abf8-e0662796d09d",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "OxB0Vkr36IrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from evaluate import load\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from accelerate import Accelerator\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def compute_metric(predictions, references, total_loss, loader, metric):\n",
        "    metrics_result = metric.compute(predictions=predictions, references=references)\n",
        "    metrics = metrics_result['accuracy']\n",
        "    loss = total_loss / len(loader)\n",
        "    return metrics, loss\n",
        "\n",
        "\n",
        "def dataset(dataset_name, batch_size, tokenizer):\n",
        "    dataset = load_dataset(dataset_name, 'mrpc')\n",
        "\n",
        "    def encode(examples):\n",
        "        return tokenizer(examples['sentence1'], examples['sentence2'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "    dataset = dataset.map(encode, batched=True)\n",
        "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    train_dataset = dataset['train']\n",
        "    eval_dataset = dataset['validation']\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
        "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
        "\n",
        "    return train_loader, eval_loader\n",
        "\n",
        "\n",
        "def train(epoch, model, loader, optimizer, accelerator, metric):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_references = []\n",
        "    loop = tqdm(loader, desc=f\"Training Epoch {epoch}\", disable=not accelerator.is_local_main_process)\n",
        "    for batch in loop:\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        optimizer.zero_grad()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
        "        references = batch['labels'].detach().cpu().numpy()\n",
        "        all_predictions.extend(predictions)\n",
        "        all_references.extend(references)\n",
        "\n",
        "    # Compute accuracy using evaluate\n",
        "    train_accuracy, train_loss = compute_metric(all_predictions, all_references, total_loss, loader, metric)\n",
        "    return train_accuracy, train_loss\n",
        "\n",
        "\n",
        "\n",
        "# Evaluation function without tqdm\n",
        "def evaluate(model, loader, metric):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_references = []\n",
        "    for batch in loader:\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predictions = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
        "            references = batch['labels'].detach().cpu().numpy()\n",
        "            all_predictions.extend(predictions)\n",
        "            all_references.extend(references)\n",
        "\n",
        "    # Compute accuracy using evaluate\n",
        "    valid_accuracy, valid_loss = compute_metric(all_predictions, all_references, total_loss, loader, metric)\n",
        "    return valid_accuracy, valid_loss\n",
        "\n",
        "\n",
        "def main():\n",
        "# Initiate Accelerator\n",
        "    accelerator = Accelerator()\n",
        "\n",
        "# Download Model and Tokenizer\n",
        "    checkpoint = 'bert-base-uncased'\n",
        "    model = BertForSequenceClassification.from_pretrained(checkpoint, force_download=True, num_labels=2)\n",
        "    tokenizer = BertTokenizer.from_pretrained(checkpoint, force_download=True)\n",
        "\n",
        "# Setting up Hyperparameters\n",
        "    epochs = 10\n",
        "    lr = 5e-4\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "    batch_size = 128\n",
        "    metric = load(\"accuracy\")\n",
        "\n",
        "# Processing Dataset\n",
        "    dataset_name = 'glue'\n",
        "    train_loader, eval_loader = dataset(dataset_name, batch_size, tokenizer)\n",
        "\n",
        "# Preparing components for Accelerate\n",
        "    model, optimizer, train_loader, eval_loader = accelerator.prepare(model, optimizer, train_loader, eval_loader)\n",
        "\n",
        "# Fitting the Model\n",
        "    for epoch in range(1, epochs+1):  # Training for 3 epochs\n",
        "        train_accuracy, train_loss = train(epoch, model, train_loader, optimizer, accelerator, metric)\n",
        "        validation_accuracy, validation_loss = evaluate(model, eval_loader, metric)\n",
        "\n",
        "        if accelerator.is_local_main_process:\n",
        "            print(f\"Training Accuracy: {train_accuracy:.4f}, Training Loss: {train_loss:.4f}\")\n",
        "            print(f\"Validation Accuracy: {validation_accuracy:.4f}, Validation Loss: {validation_loss:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from accelerate import notebook_launcher\n",
        "    notebook_launcher(main, num_processes=2, mixed_precision=\"fp16\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "KY1oi08H6IrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_content=\"\"\"\n",
        "import torch\n",
        "from evaluate import load\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from accelerate import Accelerator\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def compute_metric(predictions, references, total_loss, loader, metric, custom=\"no\"):\n",
        "    if custom==\"yes\":\n",
        "        print(\"hello\")\n",
        "    else:\n",
        "        metrics_result = metric.compute(predictions=predictions, references=references)\n",
        "        metrics = metrics_result['accuracy']\n",
        "        loss = total_loss / len(loader)\n",
        "        return metrics, loss\n",
        "\n",
        "\n",
        "def dataset(dataset_name, batch_size, tokenizer):\n",
        "    dataset = load_dataset(dataset_name, 'mrpc')\n",
        "\n",
        "    def encode(examples):\n",
        "        return tokenizer(examples['sentence1'], examples['sentence2'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "    dataset = dataset.map(encode, batched=True)\n",
        "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    train_dataset = dataset['train']\n",
        "    eval_dataset = dataset['validation']\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
        "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
        "\n",
        "    return train_loader, eval_loader\n",
        "\n",
        "\n",
        "def train(epoch, model, loader, optimizer, accelerator, metric):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_references = []\n",
        "    loop = tqdm(loader, desc=f\"Training Epoch {epoch}\", disable=not accelerator.is_local_main_process)\n",
        "    for batch in loop:\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        optimizer.zero_grad()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
        "        references = batch['labels'].detach().cpu().numpy()\n",
        "        all_predictions.extend(predictions)\n",
        "        all_references.extend(references)\n",
        "\n",
        "    # Compute accuracy using evaluate\n",
        "    train_accuracy, train_loss = compute_metric(all_predictions, all_references, total_loss, loader, metric)\n",
        "    return train_accuracy, train_loss\n",
        "\n",
        "\n",
        "\n",
        "# Evaluation function without tqdm\n",
        "def evaluate(model, loader, metric):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_references = []\n",
        "    for batch in loader:\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predictions = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
        "            references = batch['labels'].detach().cpu().numpy()\n",
        "            all_predictions.extend(predictions)\n",
        "            all_references.extend(references)\n",
        "\n",
        "    # Compute accuracy using evaluate\n",
        "    valid_accuracy, valid_loss = compute_metric(all_predictions, all_references, total_loss, loader, metric)\n",
        "    return valid_accuracy, valid_loss\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "# Initiate Accelerator\n",
        "    accelerator = Accelerator()\n",
        "\n",
        "# Download Model and Tokenizer\n",
        "    checkpoint = 'bert-base-uncased'\n",
        "    model = BertForSequenceClassification.from_pretrained(checkpoint, force_download=True, num_labels=2)\n",
        "    tokenizer = BertTokenizer.from_pretrained(checkpoint, force_download=True)\n",
        "\n",
        "# Setting up Hyperparameters\n",
        "    epochs = 10\n",
        "    lr = 5e-4\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "    batch_size = 128\n",
        "    metric = load(\"accuracy\")\n",
        "\n",
        "# Processing Dataset\n",
        "    dataset_name = 'glue'\n",
        "    train_loader, eval_loader = dataset(dataset_name, batch_size, tokenizer)\n",
        "\n",
        "# Preparing components for Accelerate\n",
        "    model, optimizer, train_loader, eval_loader = accelerator.prepare(model, optimizer, train_loader, eval_loader)\n",
        "\n",
        "# Fitting the Model\n",
        "    for epoch in range(1, epochs+1):  # Training for 3 epochs\n",
        "        train_accuracy, train_loss = train(epoch, model, train_loader, optimizer, accelerator, metric)\n",
        "        validation_accuracy, validation_loss = evaluate(model, eval_loader, metric)\n",
        "\n",
        "        if accelerator.is_local_main_process:\n",
        "            print(f\"Training Accuracy: {train_accuracy:.4f}, Training Loss: {train_loss:.4f}\")\n",
        "            print(f\"Validation Accuracy: {validation_accuracy:.4f}, Validation Loss: {validation_loss:.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Create and write to the file in the /kaggle/working/ directory\n",
        "file_path = \"/kaggle/working/train_script.py\"\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(file_content)\n",
        "\n",
        "print(\"File created successfully in /kaggle/working/\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "8faEi-WY6IrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !accelerate launch --multi_gpu --num_processes=2 train_script.py\n",
        "!accelerate launch --multi_gpu --num_processes=2 --mixed_precision=fp16 train_script.py\n",
        "# !accelerate launch --multi_gpu --mixed_precision=fp16 --num_processes=2 train_script.py\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "haHJOdHO6IrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "# evaluate.list_evaluation_modules()\n",
        "predictions = [1, 0, 0 ,1]\n",
        "references = [0,0,0,1]\n",
        "metric = load(\"accuracy\")\n",
        "accuracy = metric.compute(predictions=predictions, references=references)\n",
        "accuracy"
      ],
      "metadata": {
        "trusted": true,
        "id": "zBjfPjB16IrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config"
      ],
      "metadata": {
        "trusted": true,
        "id": "ux7hB6AD6IrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -h"
      ],
      "metadata": {
        "trusted": true,
        "id": "C0jIDevz6IrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "_cell_guid": "0e12cb30-b313-4962-81b5-39055c59f197",
        "_uuid": "2fe85a82-beee-491a-9442-22c800671656",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "7oSCMo6Z6IrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the content you want to write to the file\n",
        "file_content = \"\"\"\n",
        "def hello_world():\n",
        "    print(\"Hello, World!\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    hello_world()\n",
        "\"\"\"\n",
        "\n",
        "# Create and write to the file in the /kaggle/working/ directory\n",
        "file_path = \"/kaggle/working/example.py\"\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(file_content)\n",
        "\n",
        "print(\"File created successfully in /kaggle/working/\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "9LExCBYb6IrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    num_devices = torch.cuda.device_count()\n",
        "    print(f'Using device: {device}')\n",
        "    print(f'Number of available devices: {num_devices}')"
      ],
      "metadata": {
        "id": "pNIz_VRG6IrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}